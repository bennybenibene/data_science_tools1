{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26fa8305",
   "metadata": {},
   "source": [
    "## numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d0307d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085d4ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# numpy's array method takes any list, tuple or array-like object and converts it to an ndarray\n",
    "# note that numpy arrays are of homgenous type...not mixed type like lists.\n",
    "an_array = np.array([i for i in range(10)])\n",
    "print(an_array)\n",
    "print(type(an_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d6775f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nested arrays are arrays that have arrays as values\n",
    "\n",
    "# a 0-D array is just a scalar...each value in a 1D array is a 0-D array itself\n",
    "scalar = np.array(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826dbfa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a 1-D array has scalars as its elements.  Think of a single vector of scalars.\n",
    "basic_array = np.array([1, 2, 3, 4, 5])\n",
    "print(basic_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a04ba64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a 2-D array is just an array of arrays. Think of a matrix or table.\n",
    "two_dim_array = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "print(two_dim_array)\n",
    "# we can evaluate the shape attribute of ndarrays as well\n",
    "print(two_dim_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6ce427",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a 3-D array has 2-D array elements.\n",
    "three_dim_array = np.array([[[2, 4, 6], [8, 10, 12]], [[14, 16, 18], [20, 22, 24]]])\n",
    "print(three_dim_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e097d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the ndim attribute gives the number of dimensions in an ndarray\n",
    "# Note that ndarrays can have an arbitrarily large number of dimensions.\n",
    "print(three_dim_array.ndim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e929da3f",
   "metadata": {},
   "source": [
    "## Indexing ndarrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2312a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we index 1D arrays just like lists and tuples\n",
    "one_dim = np.array([i for i in range(10)])\n",
    "print(one_dim[1:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a804e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to index 2D arrays we use comma separated values to address dimension and index\n",
    "# think of the 1st dimension as the row and the index as the column\n",
    "two_dim = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "print(two_dim[1, 2])\n",
    "print(two_dim[0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7fe18a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# higher dimensional arrays are indexed similarly, the first integer represents the first dimension,\n",
    "# the second integer represents the second dimension and so on.\n",
    "three_dim = np.array([[[1, 2, 3], [4, 5, 6]], [[7, 8, 9], [10, 11, 12]]])\n",
    "print(three_dim)\n",
    "print(three_dim[0, 1, 2]) # prints third element of second array of first array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb085da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# above the 0 allows us to access the first 2D array...see below\n",
    "print(three_dim[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6558509",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from there on the next two positions are just accessing values within the first 2D array\n",
    "print(three_dim[0, 1]) # this returns second row from first 2D array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1194f8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we're accessing the second 2D array and then the first row of that array and the second row element.\n",
    "print(three_dim[1, 0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ce5b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can use negative indexing as well.\n",
    "# Here we access the last element of the last row of the last 2D array.\n",
    "print(three_dim[-1, -1, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c834f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# and here we access the first element of the last row of the first array\n",
    "print(three_dim[0, -1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25998d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# and now the first element of the first row of the first array\n",
    "print(three_dim[0, -2, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d897bb",
   "metadata": {},
   "source": [
    "## Slicing ndarrays\n",
    "\n",
    "Slicing is also similar to what we've experienced with lists and tuples.\n",
    "We slice with [start: end] or [start: end: step]\n",
    "As before, omitting the starting index assumes zero and omitting the end assumes the length of the array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f48435b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll skip an explanation of slicing 1D arrays and jump to higher dimensions\n",
    "two_dim = np.array([[1, 2, 3, 4], [5, 6, 7, 8]])\n",
    "# Here we're slicing from index 1 to 3 of the second dimension (dimension index 1)\n",
    "print(two_dim[1, 1:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c70986",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we're accessing the last two values from both dimensions\n",
    "# This will return a 2D array\n",
    "print(two_dim[0:2, 2:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b4f624",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the following does the same as the preceding line\n",
    "print(two_dim[:, 2:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc754b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3D arrays are sliced similarly\n",
    "three_dim = np.array([[[1, 2, 3, 4], [5, 6, 7, 8]], [[9, 10, 11, 12], [13, 14, 15, 16]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7485be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# accessing last two elements of last row of second 2D array.\n",
    "print(three_dim[1, 1, 2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc02d708",
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns a 2D array\n",
    "print(three_dim[0:2, 1, 1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d34af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns a 3D array\n",
    "print(three_dim[0:2, 0:2, 1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d7fe235",
   "metadata": {},
   "source": [
    "## Data types in numpy\n",
    "\n",
    "Numpy supports strings (S), integers (i), floats (f), bools (b) and complex numbers (c)\n",
    "and also has some additional data types such as:\n",
    "unsigned integer (u), timedelta (m), datetime (M), object (O), unicode string (U)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636af892",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ndarrays have an attribute dtype that will reveal the datatype of the array\n",
    "two_dim = np.array([[1, 2, 3, 4], [5, 6, 7, 8]])\n",
    "print(two_dim.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec993eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "foo = np.array([i for i in 'abcdefg'])\n",
    "print(foo.dtype)\n",
    "# notice that the dtype here was unicode string\n",
    "# we can be explicit about the dtype when creating an array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd851f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "foo = np.array([i for i in 'abcdefg'], dtype = 'S')\n",
    "print(foo.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c03d63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# size can also be specified for i, u, f, S and U\n",
    "foo = np.array([15, 16, 17, 16,], dtype = 'S2')\n",
    "print(foo.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3017c150",
   "metadata": {},
   "outputs": [],
   "source": [
    "# notice what happens when we specify single byte string dtype with these ints...our values are truncated.\n",
    "foo = np.array([15, 16, 17, 16,], dtype = 'S1')\n",
    "print(foo)\n",
    "# an exception will occur if you try to specify a dtype to which the values in the array can't be cast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a165efae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# oftentimes you need to cast an entire array to another type\n",
    "# numpy offers the method astype() which takes the new type as a parameter and returns a copy.\n",
    "# datatypes can be specified with the single char version or the name. For example 'f' or float.\n",
    "\n",
    "an_array = np.array([1, 2, 3, 4, 5])\n",
    "an_array.astype('S') # this will just return a copy, so we need to assign it to a variable or overwrite it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b6b961",
   "metadata": {},
   "outputs": [],
   "source": [
    "an_array = an_array.astype('S')\n",
    "print(an_array.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb1f693",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy() and view() methods\n",
    "# These concepts are related to the aliasing of variables\n",
    "\n",
    "# In numpy we can use the copy() method to make copies of arrays.\n",
    "# Changes made to the original or the copy have no impact on another.\n",
    "# A view() of an array just points to the original array, so changes made\n",
    "# to the original or the view will impact the other.\n",
    "\n",
    "# .copy()\n",
    "an_array = np.array([1, 2, 3, 4])\n",
    "a_copy = an_array.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f43485",
   "metadata": {},
   "outputs": [],
   "source": [
    "an_array[0] = 99\n",
    "a_copy[1] = 99\n",
    "\n",
    "print(an_array)\n",
    "print(a_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec0fa3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# .view()\n",
    "an_array = np.array([1, 2, 3, 4])\n",
    "a_view = an_array.view()\n",
    "\n",
    "an_array[0] = 99\n",
    "a_view[1] = 99\n",
    "\n",
    "print(an_array)\n",
    "print(a_view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3bf5268",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can think about this in terms of ownership of the data.\n",
    "# A copy owns the data and a view does not.\n",
    "# Data ownership can be assessed using the base attribute of an ndarray.\n",
    "\n",
    "an_array = np.array([1, 2, 3, 4])\n",
    "a_copy = an_array.copy()\n",
    "a_view = an_array.view()\n",
    "\n",
    "# If the array owns the data the base attribute will return None\n",
    "# If not the base attribute returns a reference to the original object\n",
    "print(a_copy.base)\n",
    "print(a_view.base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75cd360",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if we modify an element in the original array returned from the base attribute\n",
    "# it will modify the original array.\n",
    "a_view.base[0] = 99\n",
    "\n",
    "# now if we print the original array, the copy and the view,\n",
    "# the original and the view will have been modified by the preceding statement.\n",
    "print(an_array)\n",
    "print(a_copy)\n",
    "print(a_view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830e9919",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the shape attribute returns a tuple (of length .ndim) with the corresponding number of elements in that index\n",
    "one_dim = np.array([1, 2, 3, 4])\n",
    "two_dim = np.array([[1, 2, 3, 4], [5, 6, 7, 8]])\n",
    "three_dim = np.array([[[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12]], [[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3cb6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(one_dim.shape) # one dimension with 4 elements\n",
    "print(two_dim.shape) # two dimensions with 4 elements. Or two rows and 4 columns.\n",
    "print(three_dim.shape) # three dimensions. Two three x four 2D arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b447f895",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape()\n",
    "# The reshape method allows us to change the shape of an array or add/remove elements from dimensions.\n",
    "# You can reshape into any array as long as you have enough elements to achieve that shape.\n",
    "# for example, if we had a 1D array of length 9 then we couldn't reshape into a 2D array of shape (2, 5)\n",
    "an_array = np.array([i for i in range(1, 21)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b122392",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this, of course, won't work\n",
    "an_array.reshape(7, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97d8351",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this, however, is feasible\n",
    "new_array = an_array.reshape(4, 5)\n",
    "print(new_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a510f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# or this\n",
    "three_dim = an_array.reshape(2, 5, 2)\n",
    "print(three_dim) # now we have 3D array consisting of two five x two arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760aa690",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that reshaping returns a view\n",
    "print(an_array.reshape(2, 5, 2).base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60ac3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# so if we alter a value in the reshaped array then we'll alter the original array we reshaped.\n",
    "an_array.reshape(2, 5, 2)[0, 0, 0] = 99\n",
    "print(an_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c24452",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We assigned the reshaped object to the variable three_dim, and changes made here\n",
    "# will also be reflected in the original array\n",
    "print(three_dim.base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5296e2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this operation will also have an impact on our original array.\n",
    "three_dim[0, 0, 1] = 99\n",
    "print(an_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef454e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that we can avoid this by saving a copy of the view.\n",
    "one_dim = np.array([1, 2, 3, 4, 5, 6, 7, 8])\n",
    "two_dim = one_dim.reshape(4, 2).copy()\n",
    "two_dim[0, 0] = 99\n",
    "print(two_dim.base)\n",
    "print(two_dim)\n",
    "print(one_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f86958be",
   "metadata": {},
   "source": [
    "## np.zeros and np.ones\n",
    "\n",
    "We can also initialize the values of the array generally\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12c9bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.zeros() takes a shape and will initialize an ndarray\n",
    "print(np.zeros(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c67f960",
   "metadata": {},
   "outputs": [],
   "source": [
    "three_dim_z = np.zeros((2,3,4))\n",
    "print(three_dim_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4cf6db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.ones()\n",
    "print(np.ones(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b708281",
   "metadata": {},
   "outputs": [],
   "source": [
    "two_dim_ones = np.ones((4,4))\n",
    "print(two_dim_ones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c47686",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.random.random()\n",
    "print(np.random.random(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08be5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "two_dim_rand = np.random.random((4, 4))\n",
    "print(two_dim_rand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56777f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.arange() similar to range()...takes start stop and step values\n",
    "\n",
    "three_dim = np.arange(1, 51).reshape(5, 2, 5)\n",
    "print(three_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc55bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# operations between two vectors\n",
    "# numpy allows us to easily do operations between arrays\n",
    "print(two_dim_ones + two_dim_rand)\n",
    "print(two_dim_ones / two_dim_rand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e396e47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can also do operations between scalars and ndarrays\n",
    "# this gives us a good toolset for performing matrix operations.\n",
    "print(two_dim_ones * 1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d998cafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are a number of array methods that provide valuable aggregate information\n",
    "# .min(), .max(), .sum(), mean(), std()\n",
    "print(two_dim_rand.max())\n",
    "print(two_dim_rand.min())\n",
    "print(two_dim_rand.sum())\n",
    "print(two_dim_rand.mean())\n",
    "print(two_dim_rand.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ace0030",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the mean of first column of two_dim_rand\n",
    "print(two_dim_rand[:,0].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0abaaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can specify the axis of the ndarray to accomplish this as well\n",
    "# axis 0 computes along rows and axis 1 computes along columns\n",
    "print(two_dim_rand.mean(axis=1)) # aggregates along column, so will return means for each row\n",
    "print(two_dim_rand.mean(axis=0)) # aggregates along rows, so will return means for each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839c2888",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can calculate dot products with the .dot() method\n",
    "array_1 = np.array([1, 2, 3, 4])\n",
    "array_2 = np.array([1, -2, -3, 4])\n",
    "\n",
    "print(array_1.dot(array_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02f6bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transposition\n",
    "matrix = np.random.random((2, 4))\n",
    "print(matrix)\n",
    "print(matrix.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2be3397",
   "metadata": {},
   "source": [
    "## Iterating over ndarrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623a1fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prints elements\n",
    "for i in np.array([i for i in range(10)]):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1415abe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prints rows\n",
    "for i in np.arange(1,21).reshape(4, 5):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c81d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prints 2-D matrices\n",
    "for i in np.random.random((2,5,2)):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca79e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nditer()\n",
    "for i in np.nditer(np.random.random((2,5,2))):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68d9f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ndenumerate\n",
    "for i, j in np.ndenumerate(np.random.random((2,5,2))):\n",
    "    print(i, j)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516864cc",
   "metadata": {},
   "source": [
    "## pandas\n",
    "\n",
    "We'll discuss grouping, pivoting, merging and other more complex operations next week.  We'll start out with some pandas basics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b13a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8d205b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# note that the string argument for read_csv can be a url or a file path\n",
    "data = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8af9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153ec839",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we allowed pandas to infer the existence of a header...there are none, so let's be explicit.\n",
    "# we can set header equal to None or we can specify column names.\n",
    "\n",
    "data = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data',\n",
    "                  names=['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dab8ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()\n",
    "# that's better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d126be",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69e7d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a8cbff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve dtypes for columns\n",
    "\n",
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c091f7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# oftentimes it's helpful to have access to a sorted array of features\n",
    "for i in data.columns.sort_values():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b262bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a3ea59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# notice how we only received descriptives for the numerical fields\n",
    "data[['class']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c380bdc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# alternatively\n",
    "data.describe(include=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320914f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a481a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's define a function to do something trivial\n",
    "def split_class(cl):\n",
    "    return cl.split(\"-\")[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3844dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['species'] = data['class'].apply(split_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f73a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.nonsense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7f5966",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the column we just created inplace\n",
    "data.drop(columns='species', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340228c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.vectorize is a quicker and more effience way to apply a function taking multiple arguments to all rows of a dataframe\n",
    "def make_nonsense(cl, sw, sl):\n",
    "    if cl in ['Iris-setosa']:\n",
    "        return sw * sl\n",
    "    else:\n",
    "        return sw * (sl * 0.05)\n",
    "\n",
    "# np.vectorize takes a function and returns a vectorized function\n",
    "data['nonsense'] = np.vectorize(make_nonsense)(data['class'], data['sepal_width'], data['sepal_length'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3ef5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.nonsense)\n",
    "data.drop(columns='nonsense', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794e06e2",
   "metadata": {},
   "source": [
    "## indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a96050",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[data['class'] == 'Iris-setosa', :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0a3fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[data['class'] == 'Iris-setosa', ['sepal_width', 'sepal_length']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b9d0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iloc for integer based indexing\n",
    "data.iloc[:, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8177de2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.iloc[0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a97396b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.iloc[:2, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fce6010",
   "metadata": {},
   "outputs": [],
   "source": [
    "# isolating row indices meeting a condition\n",
    "location = data.index[(data['class'] == 'foo')].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901a05b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(index=location, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa49988d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating dataframes from dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dda1fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the DataFrame function\n",
    "a_dict = {'name': ['Randy', 'Gerald', 'Susan', 'Louise'],\n",
    "         'age': [45, 45, 41, 48],\n",
    "         'nickname': ['Rand', 'Ger', 'Susie', 'Weezy'],\n",
    "         'id': ['871', '872', '873', '874']}\n",
    "a_df = DataFrame(a_dict)\n",
    "print(a_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e49c813",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the .from_dict method\n",
    "a_df = DataFrame.from_dict(a_dict)\n",
    "print(a_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91ff19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# note that .from_dict has an 'orient' argument. If keys should be columns\n",
    "# pass 'columns' to orient (default behavior).  If keys should be row indices \n",
    "# pass 'index' to this parameter.  See below..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cae7e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_df = DataFrame.from_dict(a_dict, orient='index')\n",
    "print(a_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5c5614",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's go back to the original approach\n",
    "a_df = DataFrame(a_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adcee4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_df.set_index('id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60fde020",
   "metadata": {},
   "outputs": [],
   "source": [
    "# notice that our row indices are now the id values.  The index object now has a name attribute.\n",
    "a_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a1f9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# say we want to store our index values as a column and revert back to integer-based indexing.\n",
    "a_df.reset_index(drop=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50931f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf50e765",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's rename a column\n",
    "a_df.rename(columns={'name': 'first_name'},\n",
    "           inplace=True)\n",
    "\n",
    "print(a_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d45f90",
   "metadata": {},
   "source": [
    "## Let's try to parse some of our twitter returns into DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea6c090",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import base64\n",
    "from pprint import pprint\n",
    "\n",
    "with open('twitter_keys.txt') as f:\n",
    "    lines = f.readlines()\n",
    "# bearer token\n",
    "bearer_token=lines[2]\n",
    "\n",
    "def connect_to_endpoint(url, headers, params):\n",
    "    \n",
    "    \"\"\"function to execute v2 twitter api requests\"\"\"\n",
    "    \n",
    "    response = requests.get(url, headers=headers, params=params)\n",
    "    \n",
    "    print(response.status_code)\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(response.status_code, response.text)\n",
    "    return response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a5931d",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://api.twitter.com/2/tweets/search/recent\"\n",
    "\n",
    "headers = {\"Authorization\": \"Bearer {}\".format(bearer_token)} \n",
    "\n",
    "query_params = {'query': '\"Russell Wilson\" has:mentions -is:retweet has:media is:verified',\n",
    "                'max_results': 10,\n",
    "                'tweet.fields': 'id,author_id,text,geo,conversation_id,entities',\n",
    "                'expansions': 'author_id,geo.place_id',\n",
    "                'user.fields': 'name,username,verified,location',\n",
    "                'place.fields': 'country_code,geo,name,place_type'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6357160",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = connect_to_endpoint(url, headers, query_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621a80cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b7c683",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will sometime be a mess depending on the structure of your data\n",
    "df = DataFrame(data['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433408c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280cebcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we've got some redundancy in our returned fields.  We'll drop two columns.\n",
    "df.drop(columns=['conversation_id', 'edit_history_tweet_ids'],\n",
    "       inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49724b38",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d6e3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the entities variable isn't we'll suited for analysis.  \n",
    "# let's take a closer look at it.  \n",
    "print(type(df.loc[0, 'entities']))\n",
    "pprint(df.loc[0, 'entities'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ef835f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perhaps we just want the mentions\n",
    "def count_mentions(ent):\n",
    "    return len(ent['mentions'])\n",
    "\n",
    "df['mention_count'] = np.vectorize(count_mentions)(df['entities'])\n",
    "\n",
    "print(df[['mention_count']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fdf6da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perhaps we're done with the entities column\n",
    "# let's drop it\n",
    "df.drop(columns='entities',\n",
    "       inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b30018",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remember, our return object was a dictionary with three keys.\n",
    "# the 'data' key points to the majority of the tweet info,\n",
    "# but we also have 'meta' and 'includes'.  We'll ignore 'meta' for now.\n",
    "# all of the includes data is associated with a 'users' key.\n",
    "\n",
    "# these are the user.fields data we requested: name, username, verified, location\n",
    "# not all records will necesarily have all keys.\n",
    "\n",
    "pprint(data['includes'])\n",
    "\n",
    "#user_df = DataFrame(data['includes']['users'])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d99597",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's create a user DataFrame\n",
    "user_df = DataFrame(data['includes']['users'])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d25ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65d15f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# an alternative appraoch is to create a generator.  You'll see this in HW4\n",
    "import copy\n",
    "\n",
    "def user_generator(users):\n",
    "    for user in users:\n",
    "        user_copy = copy.deepcopy(user)\n",
    "        yield user_copy\n",
    "\n",
    "user_df2 = DataFrame(user_generator(data['includes']['users']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ad166d",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0575cb55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's merge these....we'll talk more about merging next week.\n",
    "\n",
    "# notice that we have duplication between the two tables in terms of column names\n",
    "# these will have _x, _y, etc. appended to the names. We can change names before\n",
    "# to avoid this behavoir.  Afterwards is fine too.\n",
    "\n",
    "df.rename(columns={'id':'tweet_id'}, inplace=True)\n",
    "\n",
    "df = df.merge(user_df, how='left', left_on='author_id', right_on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa84cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tools_venv",
   "language": "python",
   "name": "tools_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
