{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas DataFrame for storing tweet feed (total 12 points)\n",
    "\n",
    "Creating the following date frame for storing tweets:\n",
    "\n",
    "- **climate_feed_df** DataFrame for storing tweets\n",
    "- **retweeted_status_df** for storing original tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as bsp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pickle files retweeted_status_df.pkl and climate_feed.pkl should be in the same folder as this notebook.\n",
    "If needed, they can also be downloaded by uncommenting the commands below.  There are csv files of these posted on 2DU under the files section if you are unable to read the pkl files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://github.com/psnegi/data_science_tools1/raw/master/hws/retweeted_status_df.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://github.com/psnegi/data_science_tools1/raw/master/hws/climate_feed.pkl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color= \"red\">Click on these links if the above downloads fail. </font>\n",
    "\n",
    "\n",
    "https://github.com/psnegi/data_science_tools1/raw/master/hws/climate_feed.pkl\n",
    "\n",
    "https://github.com/psnegi/data_science_tools1/raw/master/hws/retweeted_status_df.pkl\n",
    "\n",
    "Keep these pickle files in the same directory as the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retweeted_status_df = pd.read_pickle(\"./retweeted_status_df.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retweeted_status_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#climate_feed_df.to_pickle(\"./climate_feed.pkl\")\n",
    "climate_feed_df = pd.read_pickle(\"./climate_feed.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "climate_feed_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are dtypes for climate_feed_df. We'll work with only\n",
    "- entities to extract hashtags\n",
    "- retweeted_status in case we need to extract original full tweet\n",
    "- truncated\n",
    "- text: tweet text\n",
    "- created_at\n",
    "- user_id\n",
    "\n",
    "Some of them have wrong datatypes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "climate_feed_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1 (0.5 point) Replace None with nan in climate_feed_df. Also display some random rows.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Working with only selected attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "climate_feed_df = climate_feed_df[['created_at', 'entities','retweeted_status', 'truncated', 'user_id', 'text' ]].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "climate_feed_df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2 (0.5 point) convert\n",
    "- created_at to date time type\n",
    "- truncated to bool type.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking datatype again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "climate_feed_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q3(1 point) In climate_feed_df, calculate the number of NAN values in various columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use **ast** module to parse string to python dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q4(3 points) Using *ast* module  convert entities to python dictionary. This dictionary should contain hashtags and user_mentions\n",
    " - Create a column named hashtags. Values in this columns should be comma separated values of **text** attribute in **hashtags**  value.\n",
    " - Create a column named user_mentions. Values in this columns should be command separated values of **name** attribute in **user_mentions** values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning tweets\n",
    "\n",
    "Let's see some random tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_length = 280\n",
    "pd.set_option('max_colwidth', 2*tweet_length)\n",
    "climate_feed_df['text'].sample(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example of tweet not truncated**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "climate_feed_df['text'].loc[3929]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exampe of tweet truncated**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "climate_feed_df['text'].loc[3928]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Truncated tweet has three horizontal ellipses in it. One can check retweeted_status values and \n",
    "use it got the the original tweet text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "climate_feed_df.retweeted_status.loc[3928]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retweeted_status_df[retweeted_status_df.id == climate_feed_df.retweeted_status.loc[3928]].text.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is url above tweet. We can use **requests** to get the complete text.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q5(3 points) Perform following activities for creating a new original_tweet_text field in climate_feed_df. \n",
    "\n",
    "If a record from climate_feed_df has a valid **retweeted_status** value (i.e., it's not null) then search for the original text in retweeted_status_df **text** column.  The text of the tweet in retweeted_status_df will have a url.  This is the url for the original tweet.  On the other hand, if the **truncated** value in climate_feed_df is True, then the record won't have a valid retweet id (it's not a retweet) and the **text** value in climate_feed_df will contain the link to the original tweet.\n",
    "\n",
    "Search for the original text in retweeted_status_df for tweets with a valid **retweeted_status**.  Store this value in a new column in climate_feed_df called **final_tweet_text**.  I there is not a valid **retweeted_status** in climate_feed_df, then use the value from the **text** column in climate_feed_df.\n",
    "\n",
    "Finally, create the field **original_tweet_link** in climate_feed_df.  This will be the link to the original tweet which can be obtained from the text field in retweeted_status_df.\n",
    "\n",
    "Note that we could then use the URLs to retrieve the full tweet text.  This was the requirement of the original assignmnet.  We won't do anything with the URLs except practice extracting them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q 6(2 points) Remove all the references  of RT and  @user: or @user, and url in climate_feed_df text attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Emoji detection\n",
    "\n",
    "See this example of emoji as unicode characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "climate_feed_df['text'].loc[3931]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use use regex to capture this emoji\n",
    "\n",
    "https://apps.timwhitlock.info/emoji/tables/unicode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emoji_regex = re.compile(r\"\\U0001F631\", re.UNICODE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emoji_regex.findall(climate_feed_df['text'].loc[3931])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use emoji and/or demoji libraries to make this task easier.  Feel free to use whatever approach you like here.\n",
    "\n",
    "Here is some documentation about unicode support in python\n",
    "\n",
    "https://docs.python.org/3/howto/unicode.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install demoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import emoji\n",
    "import demoji"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q 8(2 points) Create a column  called *emoji*.  This column should contain a list of tuples for emoji detected in *text*. The first element of the tuple is the emoji detected and second is the text describing the emoji."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write code here\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tools_venv",
   "language": "python",
   "name": "tools_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
